{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84a3587",
   "metadata": {},
   "source": [
    "Solution to Q1 and Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "driver = webdriver.Chrome(r\"/Users/pallavishu/Downloads/chromedriver\")\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product = driver.find_element(By.XPATH,'//input[@type=\"text\" and @class=\"nav-input nav-progressive-attribute\"]')\n",
    "product.send_keys(\"Guitar\")\n",
    "search = driver.find_element(By.XPATH,'//input[@type=\"submit\" and @class=\"nav-input nav-progressive-attribute\"]')\n",
    "search.click()\n",
    "url_class = driver.find_element(By.CLASS_NAME,\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\")\n",
    "url = []\n",
    "start = 0\n",
    "end =3\n",
    "name=[]\n",
    "link=[]\n",
    "price=[]\n",
    "delivery=[]\n",
    "for page in range(start,end):\n",
    "    name=page.find_element(By.XPATH,'//h2[@class = \"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]').a.span.text\n",
    "    link=page.find_element(By.XPATH,'//span[@class = \"s-image\"]').get_attribute('src')\n",
    "    Price=page.find_element(By.XPATH,'//span[@class = \"a-offscreen\"]').text\n",
    "    delivery =page.find_element(By.XPATH,'//span[@class = \"a-color-base a-text-bold\"]').text\n",
    "df = pd.DataFrame({'ProductName':name,'URL':link, 'Price': price,'Delivery':})\n",
    "df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058bfc3e",
   "metadata": {},
   "source": [
    "Solution to Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a34bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "driver = webdriver.Chrome(r\"/Users/pallavishu/Downloads/chromedriver\")\n",
    "driver.get(\"https://images.google.com/\")\n",
    "searchInput  = driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input\")\n",
    "searchItems = ['fruits','cars','machine learning','guitar','cakes']\n",
    "allData = []\n",
    "#for i in searchItem:\n",
    "for j in searchItems:\n",
    "    temp = {}\n",
    "    temp[\"searchItem\"] = j\n",
    "    try:\n",
    "        searchInput.send_keys(j)\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"Refreshing page\")\n",
    "        j.get(\"https://images.google.com/\")\n",
    "    searchButton = j.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/button/div\")\n",
    "    searchButton.click()\n",
    "    count  = 0\n",
    "    imageData = {}\n",
    "    fruitsImgs = j.find_elements(By.XPATH,'//img[@class = \"rg_i Q4LuWd\"]')\n",
    "    for i in fruitsImgs:\n",
    "        if count < 10:\n",
    "            temp[\"links\"] = i.get_attribute('src')\n",
    "            count = count + 1\n",
    "            allData.append(temp)\n",
    "df = pd.DataFrame(allData)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7649b39",
   "metadata": {},
   "source": [
    "Solution to Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "driver = webdriver.Chrome(r\"/Users/pallavishu/Downloads/chromedriver\")\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"smartphone\")\n",
    "search = driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()\n",
    "phone = driver.find_elements(By.XPATH,'//a[@class=\"_1fQZEK\"]')\n",
    "for all i in phone:\n",
    "    phones ={}\n",
    "    phones['Smartphonename']=i.find_element(By.CLASS_NAME,\"_4rR01T\").text\n",
    "    details = i.find_elements(By.CLASS_NAME,\"rgWa7D\")\n",
    "    temp1 =details[0].text\n",
    "    temp2 =details[2].text\n",
    "    phones['RAM']=temp1.text.split('|')[0]\n",
    "    phones['Storage']=temp1.text.split('|')[1]\n",
    "    phones['PrimaryCamera']=temp2.text.split('|')[1]\n",
    "    phones['SecondaryCamera']=temp2.text.split('|')[0]\n",
    "    phones['DisplaySize']=details[1].text\n",
    "    phones['BatteryCapacity']=details[3].text\n",
    "    phones['Price']=i.div.find_elements(By.CLASS_NAME,\"_30jeq3 _1_WHN1\").text\n",
    "    phones['ProductURL']=i.get_attribute('href')\n",
    "    allPhones.append(phones)\n",
    "df = pd.DataFrame(allPhones)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783193ea",
   "metadata": {},
   "source": [
    "Solution to Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca922d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "driver = webdriver.Chrome(r\"/Users/pallavishu/Downloads/chromedriver\")\n",
    "driver.get(\"https://www.google.com/maps\")\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.element_to_be_clickable((By.ID, \"searchboxinput\"))).send_keys(\"New York\")\n",
    "wait.until(EC.element_to_be_clickable((By.ID, \"searchbox-searchbutton\"))).click()\n",
    "time.sleep(15)\n",
    "ActionChains(driver).move_to_element(driver.find_element(By.XPATH, \"//html/body\")).context_click().perform()\n",
    "print(wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"ul[role='menu']>li div div[class*='text']:nth-of-type(1)\"))).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b212211",
   "metadata": {},
   "source": [
    "Solution to Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://trak.in/india-startup-funding-investment-2015/')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "januaryTable = soup.find('table',id = \"tablepress-54\" )\n",
    "FebTable = soup.find('table',id = \"tablepress-55\" )\n",
    "MarchTable = soup.find('table',id = \"tablepress-56\" )\n",
    "\n",
    "JanuaryData =[]\n",
    "FebruaryData =[]\n",
    "MarchData =[]\n",
    "for row in januaryTable.tbody.findAll('tr'):\n",
    "    AllData = {}\n",
    "    AllData[\"Date\"] = row.findAll(\"td\")[1].text\n",
    "    AllData[\"StartupName\"] = row.findAll(\"td\")[2].text\n",
    "    AllData[\"Industry\"] = row.findAll(\"td\")[3].text\n",
    "    AllData[\"SubVertical\"] = row.findAll(\"td\")[4].text\n",
    "    AllData[\"City\"] = row.findAll(\"td\")[5].text\n",
    "    AllData[\"InvestorName\"] = row.findAll(\"td\")[6].text\n",
    "    AllData[\"InvestmentType\"] = row.findAll(\"td\")[7].text\n",
    "    AllData[\"Amount\"] = row.findAll(\"td\")[8].text\n",
    "    JanuaryData.append(AllData)\n",
    "Jandf = pd.DataFrame(JanuaryData)\n",
    "print(\"January Data is: \\n\\n\",Jandf)\n",
    "\n",
    "\n",
    "for row in FebTable.tbody.findAll('tr'):\n",
    "    AllData = {}\n",
    "    AllData[\"Date\"] = row.findAll(\"td\")[1].text\n",
    "    AllData[\"StartupName\"] = row.findAll(\"td\")[2].text\n",
    "    AllData[\"Industry\"] = row.findAll(\"td\")[3].text\n",
    "    AllData[\"SubVertical\"] = row.findAll(\"td\")[4].text\n",
    "    AllData[\"City\"] = row.findAll(\"td\")[5].text\n",
    "    AllData[\"InvestorName\"] = row.findAll(\"td\")[6].text\n",
    "    AllData[\"InvestmentType\"] = row.findAll(\"td\")[7].text\n",
    "    AllData[\"Amount\"] = row.findAll(\"td\")[8].text\n",
    "    FebruaryData.append(AllData)\n",
    "Febdf = pd.DataFrame(FebruaryData)\n",
    "print(\"February Data is: \\n\\n\",Febdf)\n",
    "\n",
    "\n",
    "for row in MarchTable.tbody.findAll('tr'):\n",
    "    AllData = {}\n",
    "    AllData[\"Date\"] = row.findAll(\"td\")[1].text\n",
    "    AllData[\"StartupName\"] = row.findAll(\"td\")[2].text\n",
    "    AllData[\"Industry\"] = row.findAll(\"td\")[3].text\n",
    "    AllData[\"SubVertical\"] = row.findAll(\"td\")[4].text\n",
    "    AllData[\"City\"] = row.findAll(\"td\")[5].text\n",
    "    AllData[\"InvestorName\"] = row.findAll(\"td\")[6].text\n",
    "    AllData[\"InvestmentType\"] = row.findAll(\"td\")[7].text\n",
    "    AllData[\"Amount\"] = row.findAll(\"td\")[8].text\n",
    "    MarchData.append(AllData)\n",
    "Marchdf = pd.DataFrame(MarchData)\n",
    "print(\"March Data is: \\n\\n\",Marchdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a35ed",
   "metadata": {},
   "source": [
    "Solution to Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "driver = webdriver.Chrome(r\"/Users/pallavishu/Downloads/chromedriver\")\n",
    "driver.get(\"https://www.digit.in/\")\n",
    "price_filter = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[4]/ul/li[7]/a')\n",
    "price_filter.click()\n",
    "color_filter = driver.find_element(By.XPATH,'/html/body/div[7]/div/div/div[2]/div/div[2]/div')\n",
    "color_filter.click()\n",
    "allData = driver.find_element(By.XPATH,'/html/body/div[7]/div[2]/div/div/div/div/div[1]/div[2]')\n",
    "allLaptop = []\n",
    "for i in allData.find_elements(By.tagName(\"p\")):\n",
    "    laptop={}\n",
    "    laptop[\"Name\"]=i.p[2].em.text\n",
    "    laptop[\"Description\"] = i.p[3].text\n",
    "    allLaptop.append(laptop)\n",
    "df=pd.DataFrame(allLaptop)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd719ec6",
   "metadata": {},
   "source": [
    "Solution to Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40026b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.forbes.com/billionaires/')\n",
    "soup = BeautifulSoup(page.content,'html5lib')\n",
    "allData = soup.find('div', class_='table-row-group__container')\n",
    "print(allData)\n",
    "allBillionares = []\n",
    "for i in allData.findAll('div',class_ =\"table-row \" and class_ =\"table-row expanded\"):\n",
    "    billionares = {}\n",
    "    billionares['Rank'] = i.div[0].text\n",
    "    billionares['Name'] =i.div[1].div.text\n",
    "    billionares['Net worth'] =i.div[2].div.text\n",
    "    billionares['Age'] =i.div[3].div.text\n",
    "    billionares['Citizenship'] =i.div[4].text\n",
    "    billionares['Source'] =i.div[5].div.div.span.text\n",
    "    billionares['Industry'] =i.div[6].div.div.span.text\n",
    "    allBillionares.append(billionares)\n",
    "df = pd.DataFrame(allBillionares)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138719c",
   "metadata": {},
   "source": [
    "Solution to Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.youtube.com/watch?v=f1ikpsmiqPY')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "acDiv = soup.find('div', id = \"contents\" )\n",
    "count =1\n",
    "allData =[]\n",
    "for row in acDiv.findAll(\"ytd-comment-thread-renderer\",class_= \"style-scope ytd-item-section-renderer\")[1:]:\n",
    "    if count <= 500:\n",
    "        AllComment ={}\n",
    "        temp1 = row.ytd-comment-renderer.findAll('div')[2]\n",
    "        temp2 = temp.findAll('div')[1]\n",
    "        temp32 = temp.findAll('div')[1]\n",
    "        temp4 =temp2.findAll('div')[2]\n",
    "        AllComment[\"Comment\"] = temp4.ytd-expander.div.yt-formatted-string.text\n",
    "        AllComment[\"time\"] = temp32.yt-formatted-string.a.text\n",
    "        AllComment[\"Upvote\"] = temp2.ytd-comment-action-buttons-renderer.div.span.text\n",
    "        count = count + 1\n",
    "        allData.append(AllData)\n",
    "df = pd.DataFrame(allData)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a65825",
   "metadata": {},
   "source": [
    "Solution to Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.hostelworld.com/s?q=London,%20England&country=England&city=London&type=city&id=3&from=2022-08-28&to=2022-08-31&guests=2&page=1')\n",
    "soup =BeautifulSoup(page.content, 'html5lib')\n",
    "details = []\n",
    "for row in soup.findAll('div', class_ = \"property\"):\n",
    "    Details = {}\n",
    "    titleDiv = row.find('div',class_ = \"title-row\")\n",
    "    Details[\"Title\"] = titleDiv.a.text\n",
    "    Details[\"Location\"] = titleDiv.div.a.text\n",
    "    details.append(Details)\n",
    "df = pd.DataFrame(details)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7639fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c84508d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
