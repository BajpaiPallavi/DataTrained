{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19f7ca2",
   "metadata": {},
   "source": [
    "Solution to Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31207cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108df24",
   "metadata": {},
   "source": [
    "Solution to Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.imdb.com/list/ls009997493/')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "allMovie = soup.find('div', class_=\"lister list detail sub-list\")\n",
    "movies = []\n",
    "for row in allMovie.findAll('div',class_=\"lister-item mode-detail\"):\n",
    "    movie= {}\n",
    "    movie['Name'] =row.h3.a.text\n",
    "    temp=row.h3.text\n",
    "    temp= temp.split(\"\\n\")[4]\n",
    "    movie['Year of release'] = temp[5:9]\n",
    "    movie['Rating'] = row.find('span',class_=\"ipl-rating-star__rating\").text\n",
    "    movies.append(movie)\n",
    "df = pd.DataFrame(movies)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63155c20",
   "metadata": {},
   "source": [
    "Solution to Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dff13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "allMovie = soup.find('tbody', class_=\"lister-list\")\n",
    "movies=[]\n",
    "count = 1\n",
    "for row in allMovie.findAll('tr'):\n",
    "    movie = {} \n",
    "    movie['Name'] =row.find('td',class_=\"titleColumn\").a.text\n",
    "    movie['Rating'] = row.find('td',class_=\"ratingColumn imdbRating\").strong.text\n",
    "    tempYOR = row.find('td',class_=\"titleColumn\").span.text\n",
    "    movie['Year of release'] = tempYOR[1:5]\n",
    "    movies.append(movie)\n",
    "    count = count + 1\n",
    "    if count > 100:\n",
    "        break\n",
    "df = pd.DataFrame(movies)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442f1b9",
   "metadata": {},
   "source": [
    "Solution to Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup =BeautifulSoup(page.content, 'html5lib')\n",
    "allPresidents = soup.find('ul',class_ = 'listing cf')\n",
    "presidents = []\n",
    "for row in allPresidents.findAll('li'):\n",
    "    president = {}\n",
    "    president['Name'] = row.div.h3.text.split('(')[0]\n",
    "    president['YOB'] = row.div.h3.text.split('(')[1]\n",
    "    president['TOO'] = row.div.p.text.split(':')[1]\n",
    "    presidents.append(president)\n",
    "    #print(president)\n",
    "df = pd.DataFrame(presidents)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edac843",
   "metadata": {},
   "source": [
    "Solution to Q5(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "allTeams = soup.find('tbody')\n",
    "teams = []\n",
    "count = 1\n",
    "for row in allTeams.findAll('tr'):\n",
    "    team = {}\n",
    "    team['Name'] = row.find('span',class_='u-hide-phablet').text\n",
    "    team['Matches']= row.find('td', class_=['table-body__cell u-center-text','rankings-block__banner--matches']).text\n",
    "    team['Points'] = row.findAll('td')[3].text\n",
    "    team['Rating'] = row.findAll('td')[4].text\n",
    "    teams.append(team)\n",
    "    count = count + 1\n",
    "    print(row.findAll('td'))\n",
    "    if count > 100:\n",
    "        break\n",
    "df = pd.DataFrame(teams)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab992b",
   "metadata": {},
   "source": [
    "Solution to Q5(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9584b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#import re\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "l1 = [] \n",
    "count = 1\n",
    "for element in soup.select('[class=\"ranking-pos up\"], [class=\"ranking-pos down\"]'):\n",
    "    element.replace_with(BeautifulSoup(\"<\" + element.name + \"></\" + element.name + \">\", \"html.parser\"))\n",
    "    ranking_type = soup.select_one(\".rankings-block__title-container > h4\").text\n",
    "    for element in soup.select('table[class=\"table rankings-table\"] tr'):\n",
    "        temp = {}\n",
    "        if(element.find(\"th\")):\n",
    "            continue\n",
    "        data_dict = {}\n",
    "        for player_name in (element.select('a[href*=\"/player-rankings\"]')):\n",
    "            if(player_name.text.strip()):\n",
    "                data_dict[\"Player Name\"] = player_name.text\n",
    "        if(element.select_one('[class^=\"flag-15\"]')):\n",
    "            data_dict[\"Team Name\"] = element.select_one('[class^=\"flag-15\"]')[\"class\"][-1]\n",
    "        if(element.select_one('[class$=\"rating\"]')):\n",
    "            data_dict[\"Rating\"] = element.select_one('[class$=\"rating\"]').text\n",
    "        l1.append(data_dict)\n",
    "        count = count + 1\n",
    "    if count > 100:\n",
    "        break    \n",
    "df1 =pd.DataFrame(l1)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4aa47",
   "metadata": {},
   "source": [
    "Solution to Q5(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cabe240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#import re\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "l1 = [] \n",
    "count = 1\n",
    "for element in soup.select('[class=\"ranking-pos up\"], [class=\"ranking-pos down\"]'):\n",
    "    element.replace_with(BeautifulSoup(\"<\" + element.name + \"></\" + element.name + \">\", \"html.parser\"))\n",
    "    ranking_type = soup.select_one(\".rankings-block__title-container > h4\").text\n",
    "    for element in soup.select('table[class=\"table rankings-table\"] tr'):\n",
    "        temp = {}\n",
    "        if(element.find(\"th\")):\n",
    "            continue\n",
    "        data_dict = {}\n",
    "        for player_name in (element.select('a[href*=\"/player-rankings\"]')):\n",
    "            if(player_name.text.strip()):\n",
    "                data_dict[\"Player Name\"] = player_name.text\n",
    "        if(element.select_one('[class^=\"flag-15\"]')):\n",
    "            data_dict[\"Team Name\"] = element.select_one('[class^=\"flag-15\"]')[\"class\"][-1]\n",
    "        if(element.select_one('[class$=\"rating\"]')):\n",
    "            data_dict[\"Rating\"] = element.select_one('[class$=\"rating\"]').text\n",
    "        l1.append(data_dict)\n",
    "        count = count + 1\n",
    "    if count > 100:\n",
    "        break    \n",
    "df1 =pd.DataFrame(l1)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4509634",
   "metadata": {},
   "source": [
    "Solution to Q6(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a11653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "allTeams = soup.find('tbody')\n",
    "teams = []\n",
    "count = 1\n",
    "for row in allTeams.findAll('tr'):\n",
    "    team = {}\n",
    "    team['Name'] = row.find('span',class_='u-hide-phablet').text\n",
    "    team['Matches']= row.find('td', class_=['table-body__cell u-center-text','rankings-block__banner--matches']).text\n",
    "    team['Points'] = row.findAll('td')[3].text\n",
    "    team['Rating'] = row.findAll('td')[4].text\n",
    "    teams.append(team)\n",
    "    count = count + 1\n",
    "    if count > 100:\n",
    "        break\n",
    "df = pd.DataFrame(teams)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cfae72",
   "metadata": {},
   "source": [
    "Solution to Q6(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "l1 = [] \n",
    "count = 1\n",
    "for element in soup.select('[class=\"ranking-pos up\"], [class=\"ranking-pos down\"]'):\n",
    "    element.replace_with(BeautifulSoup(\"<\" + element.name + \"></\" + element.name + \">\", \"html.parser\"))\n",
    "    ranking_type = soup.select_one(\".rankings-block__title-container > h4\").text\n",
    "    for element in soup.select('table[class=\"table rankings-table\"] tr'):\n",
    "        temp = {}\n",
    "        if(element.find(\"th\")):\n",
    "            continue\n",
    "        data_dict = {}\n",
    "        for player_name in (element.select('a[href*=\"/player-rankings\"]')):\n",
    "            if(player_name.text.strip()):\n",
    "                data_dict[\"Player Name\"] = player_name.text\n",
    "        if(element.select_one('[class^=\"flag-15\"]')):\n",
    "            data_dict[\"Team Name\"] = element.select_one('[class^=\"flag-15\"]')[\"class\"][-1]\n",
    "        if(element.select_one('[class$=\"rating\"]')):\n",
    "            data_dict[\"Rating\"] = element.select_one('[class$=\"rating\"]').text\n",
    "        l1.append(data_dict)\n",
    "        count = count + 1\n",
    "    if count > 100:\n",
    "        break    \n",
    "df1 =pd.DataFrame(l1)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b8e92",
   "metadata": {},
   "source": [
    "Solution to Q6(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "l1 = [] \n",
    "count = 1\n",
    "for element in soup.select('[class=\"ranking-pos up\"], [class=\"ranking-pos down\"]'):\n",
    "    element.replace_with(BeautifulSoup(\"<\" + element.name + \"></\" + element.name + \">\", \"html.parser\"))\n",
    "    ranking_type = soup.select_one(\".rankings-block__title-container > h4\").text\n",
    "    for element in soup.select('table[class=\"table rankings-table\"] tr'):\n",
    "        temp = {}\n",
    "        if(element.find(\"th\")):\n",
    "            continue\n",
    "        data_dict = {}\n",
    "        for player_name in (element.select('a[href*=\"/player-rankings\"]')):\n",
    "            if(player_name.text.strip()):\n",
    "                data_dict[\"Player Name\"] = player_name.text\n",
    "        if(element.select_one('[class^=\"flag-15\"]')):\n",
    "            data_dict[\"Team Name\"] = element.select_one('[class^=\"flag-15\"]')[\"class\"][-1]\n",
    "        if(element.select_one('[class$=\"rating\"]')):\n",
    "            data_dict[\"Rating\"] = element.select_one('[class$=\"rating\"]').text\n",
    "        l1.append(data_dict)\n",
    "        count = count + 1\n",
    "    if count > 100:\n",
    "        break    \n",
    "df1 =pd.DataFrame(l1)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5295bd6",
   "metadata": {},
   "source": [
    "Solution to Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a82804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import requests\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup = BeautifulSoup(page.content,'html5lib')\n",
    "AllNews = soup.find('ul', class_= 'LatestNews-list')\n",
    "News = []\n",
    "for row in AllNews.findAll('li', class_='LatestNews-item'):\n",
    "    newz = {}\n",
    "    newz['Headline'] = row.div.div.find('a', class_ = 'LatestNews-headline').text\n",
    "    newz['Link']= row.div.div.find('a', class_ = 'LatestNews-headline')['href']\n",
    "    newz['Time']= row.div.div.span.text\n",
    "    News.append(newz)\n",
    "df = pd.DataFrame(News)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b65283",
   "metadata": {},
   "source": [
    "Solution to Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26adc0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import requests\n",
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup = BeautifulSoup(page.content,'html5lib')\n",
    "allArticles= soup.find('ul', class_='sc-9zxyh7-0 ffmPq')\n",
    "Articles = []\n",
    "for row in allArticles.findAll('li', class_='sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp'):\n",
    "    Article = {}\n",
    "    Article['Title'] = row.article.a.h2.text\n",
    "    Article['Author']= row.article.p.span.text\n",
    "    Article['Date']= row.findAll('span')[1].text\n",
    "    Article['Link'] = row.article.a['href']\n",
    "    Articles.append(Article)\n",
    "df= pd.DataFrame(Articles)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124f69e",
   "metadata": {},
   "source": [
    "Solution to Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2eb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup = BeautifulSoup(page.content,'html5lib')\n",
    "allRestaurants = soup.find('div', class_='restnt-card-wrap-new')\n",
    "restaurants = []\n",
    "for row in allRestaurants.findAll('div', class_='restnt-card restaurant'):\n",
    "    restaurant = {}\n",
    "    restaurant['Name']  = row.findAll('div')[9].a.text\n",
    "    temp1 = row.div.find('div', class_ ='restnt-detail-wrap').div.find('div',class_='detail-info').ul.li.span\n",
    "    for atag in temp1.findAll('a'):\n",
    "        restaurant['cuisine'] = temp1.text.split('|')[1]\n",
    "    restaurant['Location']= row.div.find('div', class_='restnt-detail-wrap').div.find('div',class_='restnt-info cursor').div.a.text\n",
    "    restaurant['Rating']= row.div.div.find('div', class_='restnt-rating rating-4').text\n",
    "    restaurant['ImgLink'] = row.div.div.div.img['data-src']\n",
    "    restaurants.append(restaurant)\n",
    "df = pd.DataFrame(restaurants)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0cd78",
   "metadata": {},
   "source": [
    "Solution to Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd417e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "soup = BeautifulSoup(page.content, 'html5lib')\n",
    "allPublication = soup.find('tbody')\n",
    "publications = []\n",
    "for row in allPublication.findAll('tr')[1:-1]:\n",
    "    publication = {}\n",
    "    publication['Rank'] = row.findAll('td')[0].text.split('.')[0]\n",
    "    publication['Publication'] = row.findAll('td')[1].text\n",
    "    publication['H5-Index'] = row.findAll('td')[2].text\n",
    "    publication['H5-Median'] = row.findAll('td')[3].text\n",
    "    publications.append(publication)\n",
    "df = pd.DataFrame(publications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
